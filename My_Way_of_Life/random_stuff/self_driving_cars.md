# NOTE
[Self driving cars are hard to make] > [Article Content] is where the proper outline for this speech is. Please read *that*. Also, keep in mind: this is a `MarkDown` file on *`GitHub`*. That means that is might be updated and edited in the future.

## Copyright
This work is put under `BY SA` Creative Commons copyright License. That means that others can copy this work, but they must copy the copyright notice, and they must attribute **@simon-glitch on GitHub**.

## Open source editing
Also, please **do not** edit this file. It is not appreciated by Simon Glitch.

# Self driving cars are hard to make
(for "Oral Rhetoric" course at Calvin University)

*The title is also the thesis.*

## General outline
This is the general outlne for all of the content that the article could have.

### Hardware
* cost of high quality sensors
* copyright laws lower quality
* repair cost
* faulty hardware
* trade-offs of cheap hardware
* lithium

### Software
* copyrights on software and software usage
* hacking
* malware
* bugs and redundancy
* forced arrest
* user override

### Responsibility
* drivers without licenses
* pedestrians who are trolls
* skill issues
* EMP dangers
* hardware specs *(might be a duplicate / not necessary)*
* intentional outdating (older vehicles)
* tracking pedestrians by their phone *(for their safety)*
* tracking self-driving cars
* scams
    * i.e. people who intentionally incur the probems discussed throughout this article

### AI safety
* ML is not fully understood
* when are the ML model's errors okay?
* computational costs
* evolution and updates


## Article content
### Intro
Do you ever get in the car and feel too tired to drive? Probably not very often, but there are times when you get tired of having to pay attention to the road, right? Wouldn't it be nice if you could just, *mmmmm,* take your eyes off the road for a moment? Well, you're in luck! A self-driving car (which goes my names, such as: fully autonomous vehicle, driverless vehicle, and Pedestrian Slayer <sup>TM</sup>) can drive itself, *no supervision required,* **wink,** but that's not an easy feat. You see, the car needs training, and resources, just like you do. We also have to consider various complications with the hardware, the software, and the user experience **[note a]**.

### Hardware
#### Costs
The car needs eyes, just like you. Sensory equipment on self-driving cars can be obscured by the wheather, but the best equipment is much better than the human eye in all wheather. However, the best high-quality equipment is expensive, and consumers don't have unlimited money. Well, according to [Wired] [oref 1], the equipment has gone from costing thousands of dollars to just hundreds. Also, the costs vary. Ultrasonic equipment can cost as little as $15, while a high quality GPS costs $6000. Once the industry has agreed on some standards though, the price of these items will probably come down and be settled.

#### Environmental Impact
Environmental Impact is another type of cost which environmentalists are worried about. Many companies prefer to not have to deal with this [src 9 - Goals for promoting environmental sustainability - Strategies to reduce emissions (E1) - para. 3], but mining the metals and harvesting the materials required to make these new vehicles can cause a lot of harm to the environment.

#### Electric Cars and Lithium
There's been a debate going around about electric cars requiring too much lithium, but that's not a problem that's specific to self-driving cars, *so we'll skip it.*

#### Faulty Hardware (concerns)
As the European Road Safety Observatory points out [src 11 - Section 7.1], the quality of the hardware of self-driving cars (which they call AVs) could be very important. Hardware failure is already a cause of some car crashes, and could become far more prevelant if self-driving cars remove a majority of human error. A need for diligence and redundancy could easily arise, especially if self-driving cars become too difficult to repair due to the complexity of the technology.

### Software
When hardware succeeds, software fails, or vice versa. Engineers usually have to keep both of them up equally up to date, because failures in either can lead to a catastrophe. **[note h]**

#### Hacking
Firstly, the car can be distracted and even deceived too. Self-driving cars can use the internet to learn about their environment, instead of simply relying on digital sensors. However, connecting to the internet brings security concerns. The car could be hacked [src 4: 1 Introduction, para. 1] or even just "DoS" attacked.

#### Malware
There is also the risk of the user trying to tamper with the software on their vehicle.

For example, an impatient driver might want to install a software mod that makes the car ignore speed-limits, pass other drivers on dangerous roads, cut off other drivers, and cut corners through parking lots. This same software mod could also be malware that makes the car do things the driver did not want, like intentionally hit pedestrians.

#### Bugs and redunancy
Don't forget, software can also have bugs, *and I'm not referring to ants, wasps, or cockroaches* **[note b]**. **[def: bug]**. The hardware can also cause errors, but these are very rare **[note c]**. Many computers get around this by using levels of redunancy. For example, if you try to open your email, there is a program that checks to make sure everything works correctly before you even see any emails. This means we need to be able to define exactly how our software should function. This is difficult and requires serious programming work (see: [Munish_Gupta] [oref 2]). Most modern software doesn't use the same type of reduncies as the devices in the spaceflight industry. For example, some programs use recovery code in file systems [src 7: ], but some engineers still take inspiration from projects like the Apollo missions [src 6: Lunar module lifeboat contingency] **[note i]**.

#### Forced arrest
In theory, a self-driving car can be remotely controlled by the police for safety purposes [src 1: pg 2]. It would of coure be in the interest of governments to have all self-driving cars have this capability, even though it would bring some software vulnerabilities **[note d]** [src 1: pg 21, C. Malicious or Lawful Seizures?].

#### User override
The police preventing a driver from doing harmful things is one subject, and a passenger preventing an artificial driver from doing harmful things is the opposite. [note h] In fact, these 2 systems could contradict each other in the car's software, but good programming might prevent this from being an issue.

An actual problem with letting the user override the car is that they might tell it to do unethical things. For example, a user might tell the car to do something that kills 5 pedestrians, if the alternative is the user dying. However, this would be also be a form of self defense, and there is no moral concensus on what would be ethically optimal in such a situation [src 5: GENERAL DISCUSSION, para. 1].

### Responsibility
The topic of responsibility is where there is a lot of controversy in the self-driving car industry. Self driving cars are expected to be safer than humans [src 2 - Abstract], even though their will still be traffic casualties. No matter how few casualties are caused by self-driving cars, engineers are still responsible for keeping this amount as low as possible. Car dealers, and car users (i.e. *passengers*) are *also* responsible for doing what they can to lower the number of traffic casualties.

#### Driverless passengers
Typically, a passenger is always accompanied by a human driver. However, a self-driving car can have human passengers without a human driver. The extreme example of this would be a car with multiple passengers who legally can't drive. If the passenger can't drive, then there is nothing they can do if the computer fails to operate the vehicle on its own. This could potentially leave a passenger stranded, and force them to try to illegally drive the car themself. This means that self-driving cars need to be able to reliably function while also considering the desires of their passengers. For example, a passenger should be allowed to tell the car which parking space to use, but should not be able to tell the car to drive over the speed limit. **[note e]** There are also examples where it's not so clear whether the passenger should be allowed to make a decision. For example: which lane to use on a relatively calm highway, or whether to go through a traffic light that is about to turn yellow.

#### Skill issues
**[note g]**
Driving skills are really important to human drivers in modern society, and they are equally important to artificial drivers. A self-driving car needs to be really skilled, and it needs to know how skilled it is. If the car's software is too confident, it might try an overly risky turn or manuever for the sake of saving time, and accidentally break something or injure someone. If the software isn't confident enough, it might tense up and fail to get passengers out of a dangerous situation. So, the software needs to be able to evaluate both the risks of the current situation and the risks of its potential solutions failing. This becomes even more complicated when you allow for a human driver override. The car might think that it's decision is optimal and the situation is too risky to let a human driver take control. A company might get sued if their software allows a human driver override and the prosecutor argues that the software actually would have made a better decision if allowed to handle the situation on its own.

In conclusion, the software having the right level of confidence is super important. The software needs to know when the driver has "skill issues", and also when the software might have "skill issues" that the driver does not have.

#### Income and traffic safety
Low- and middle-income level contries will have a harder time accessing and using self-driving vehicles, which means they won't benefit as much from the safety and convenience of self-driving vehicles. However, the CDC has already found that even though "only 60% of the world's vehicles are in low- and middle-income countries, 93% of [fatal incidents] occur in these countries" [src 3 - Motor Vehicle Crashes: By The Numbers, para. 1]. **[note f]** This means that these financially disadvantaged countries experience 55% more deaths per car than the average country does. If self-driving cars are not properly distributes to these countries, that percentage could be higher. That would mean the financially disadvantaged would be even more disadvantaged, in comparison to the norm, even though they wouldn't be worse off absolutely speaking.

#### Outdated software and hardware
Many vehicles currently have outdated or old hardware. This is seen as a good thing by collectors and people who like "sports" vehicles. However, a "sports" self-driving car would be very unsafe. One can hope that collectors in the future will not be trying to drive their cars with outdated AI that can be easily hacked into. However, some these cars might be able to be hacked while they are turned off, as long as they have battery life. Even a car that is 2 or 3 years out of date could be public danger, especially if it's still being used. There might be dangerous software bugs, or its sensors might be too worn down to give accurate information to the car's software, This could be solved by telling the user when the hardware is worn down and preventing the user from initiating the autonomous driving software, but some users will find this annoying and hack their own car as a workaround.

# Definitions
## Bug
In the field of software, a "bug" is any problem or flaw in the software that causes it to function incorrectly.

# Meta comments
I don't like any of the paragraphs would benefit from being longer. I would have to go into niche things, and dicuss boring details from academic sources in order to expand on any of the content at all.

Also, I'm glad I don't have any corny statements / phrases, like "can revolutionize the future of transportation and mobility".

The speech has some whole sections of this article removed. Also, there might be too many individual headers for the article. It is *technically* supposed to be an **outline**, so I guess that is okay.

Finally, I'd like to apologize for my oral presentation being sloppy. The format for this speech is really difficult to figure out, due to the complexity and variety of my topic. So, I had a hard time figuring out how to deliver so many points that are all so different from each other. Also, I didn't mention any sources in my speech; I really don't know which sources would be the most important though. Probably [source 11], but that's because it actually backs up the entire article, not just some of it.

## Lack of Sources
A lot of the details in this article are highly technical, and don't have academic sources anywhere online. These technical details require information from interviews with the companies designing self-diving cars, since the details are only really relevant to engineers. What I'm saying is that highly technical details are not relevant to most scientists and researchers.

## Ethics
Even without a lot of strong sources, and even with the industry around self-driving cars being full of a lot of controversy:
* I still think I have an unbaised description of how difficult the devices are to actually design, engineer, and develop.

## This file
This article is hosted on GitHub:
* https://github.com/simon-glitch/simon-glitch.github.io/tree/master/My_Way_of_Life/random_stuff/self_driving_cars.md

Unfortunately, GitHub won't put the "Preview" in full screen for you.

# Notes
**[a]:** This refers to the "experience" of responsibilty (or the lack of it) that users have when using a self-driving vehicle.
**[b]:** This seems off topic.
**[c]:** Why are we mentioning it if it is so rare?
**[d]:** The vulnerability would be that back door access could extend this capability beyond the police and allow bad actors to remotely control the car.
**[e]:** The rest of the paragraph might be excessive / overly verbose.
**[f]:** This might be distracting, since it changes from the topic of the thesis to the topic of some people being unfairly disadvantaged.
**[g]:** The "Skill issues" section is kinda auxiliary, but it's still an interesting point and fits in very well (at least, in a longer speech).
**[h]:** Not much can be said on a topic that is so abstract and related to details with the software implementation. Talking about this is like talking about the *Trolley Problem*, but worse, because **the subject** is software details and not ethics.
**[i]:** [src 6] only dicusses engineers in the current space industry being inspired by the past of the industry. It does not discuss interdisciplinary (or interindustrious) inspiration of any kind. So, maybe I am stretching my tounge a little too thin here by including this source.

# Other references
* 1:
    * name: Wired
    * ~"ultrasonic sensors are cheap, ranging from as little as $15 to $200"
    * ~"GPS ... its cost needs to come down significantly from the current $6,000 figure"
    * https://www.wired.com/2015/04/cost-of-sensors-autonomous-cars/
* 2:
    * name: Munish Gupta
    * site: Linked in
    * To be honest
    * https://www.linkedin.com/pulse/error-handling-large-scale-applications-munish-gupta-euutc/

# Sources
* 1:
    * name: ELIZABETH E. JOH*
    * https://www.nyulawreview.org/wp-content/uploads/2019/10/NYULawReview-94-Joh.pdf
* 2:
    * name: William Ratoff
    * text: <p style="color:green"> Every year, 1.35 million people are killed on roads worldwide and even more people are injured. Emerging self-driving car technology promises to cut this statistic down to a fraction of the current rate. On the face of it, this consideration alone constitutes a strong reason to legally require — once self-driving car technology is widely available and affordable — that all vehicles on public roads be self-driving. </p>
    * https://link.springer.com/article/10.1007/s13347-022-00551-1
* 3:
    * name: CDC
    * text: <p style="color:green"> Annually, ≈1.35 million people are killed (≈3,740 people every day) and an additional 20–50 million are injured in motor vehicle crashes. Road traffic injuries have become the leading cause of death for children and young adults aged 5–29 years. Although only 60% of the world’s vehicles are in low- and middle-income countries, 93% of the world’s crash deaths occur in these countries. More than half of people who die on the world’s roads each year are cyclists, motorcyclists, and pedestrians, also called vulnerable road users. </p>
    * https://wwwnc.cdc.gov/travel/yellowbook/2024/air-land-sea/road-and-traffic-safety
* 4:
    * name: Jacek Rak et al.
    * full name: Jacek Rak, Mario Pickavet, Kishor S. Trivedi, Javier Alonso Lopez, Arie M. C. A. Koster, James P. G. Sterbenz, Egemen K. Çetinkaya, Teresa Gomes, Matthias Gunkel, Krzysztof Walkowiak & Dimitri Staessens
    * text: <p style="color:green"> construction of perfect communication systems, as well as full prevention against various challenges and threats is not possible </p>
    * https://link.springer.com/article/10.1007/s11235-015-9987-7
* 5:
    * name: Tripat Gill
    * text: <p style="color:green"> Recently, both academic scholars and practitioners have made a concerted effort to determine the appropriate moral norms for AVs to handle such dilemmas. </p>
    * https://doi.org/10.1093/jcr/ucaa018
* 6:
    * name: Shaun Ryan and Matthew Granger
    * section: (**probably**) "Lunar module lifeboat contingency"
    * text:
        <p style="color:green"> In current proposed human spacecraft designs, there are some lessons that seem to follow from historical examples, along with some departures. For the lunar Human Landing System (HLS) program, the potential of the lander to be used as a lifeboat to the crew once they're docked to the Orion spacecraft is not the same as the architecture used on Apollo. The applicable window for such a contingency is much smaller on HLS than Apollo, as the lander and Orion don't meet until in Lunar orbit. </p>
    * https://doi.org/10.1016/j.jsse.2023.08.005
    * or: https://www.sciencedirect.com/science/article/abs/pii/S2468896723000873
* 7:
    * name: Haogang Chen et al.
    * full name: Haogang Chen, Daniel Ziegler, Adam Chlipala, M. Frans Kaashoek, Eddie Kohler,† Nickolai Zeldovich
    * text:
        <p style="color:green"> An important example of where failures matter is a file system, because developers often make subtle mistakes in recovery code, and recovery code is complex and not frequently executed. Even if such bugs are rare, they can still be costly, since they can lead to complete data loss [41]. Proving the absence of such bugs in critical software, such as a file system, is an appealing proposition. </p>
    * https://pdos.csail.mit.edu/papers/fscq:hotos15.pdf
* 8:
    * name:
    * text:
        <p style="color:green"> However, interviewees discussed contingencies of hardware, including maintenance, batteries and, most importantly, sensors. Most developers use Lidar for high-definition perception of the environment. Elon Musk has called Lidar a ‘crutch’; Tesla relies on computer vision using cheaper cameras. An AV industry consultant sought to downplay the sensor controversy: </p>
        <blockquote><p style="color:green"> Can Lidars make it happen faster? Most people say yes. He [Musk] says no … we’re waiting for a breakthrough really in computer vision [which would mean we could] use it without other sensors … Lidar is a crutch, but computer vision has one leg. So a crutch might be handy. </p></blockquote>
    * https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8586182/
* 9:
    * name: Francine Berman et al.
    * full name: Francine Berman, Emilia Cabrera, Ali Jebari, and Wassim Marrakchi
    * text: <p style="color:green"> With respect to building more energy-efficient cars, there has been a growing shift toward plug-in electric vehicles (PEVs), with recent announcements of large investments by Ford and notice that all GM vehicles will be all-electric by 2035. By 2040, it is expected that it will no longer be possible to buy a non-electric new car. Federal emission standards guide the design of today’s vehicles but have also been a cause for controversy. Many auto manufacturers want these standards loosened, while environmentalists want them strengthened. Adding to the mix is the existence of different standards in different jurisdictions; for example, California law is tougher on emissions than federal law. Public officials looking to lower emissions more aggressively may want to encourage specific jurisdictional controls that incentivize exceeding or strengthening current standards. </p>
    * https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8767286/
* 10:
    * name: Alexander Hevelke and Julian Nida-Rümelin
    * title: Responsibility for Crashes of Autonomous Vehicles: An Ethical Analysis
    * https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4430591/

* 11:
    * name: European Road Safety Observatory
    * super name: Mobility and transport - European Commission
    * title: Autonomous Vehicles & Traffic Safety
    * text:
        <p style="color:green"> ### 2.2 Motivation
        <p style="color:green"> In the face of rapid and successive developments in the transport sector, Autonomous Vehicles (AVs) and their respective technological advancements have been dominating all relevant interest. This is not without good reason, as there is high anticipation of the benefits that AVs will bring to the field. In the eventuality of complete automation (SAE Level 5 automation - see also Chapter 3), dramatic changes to all aspects of road transport are expected, including, among others, safety, mobility, accessibility, environment, infrastructure design, and goods and cargo transport. </p>
        <p style="color:green"> ... </p>
        <p style="color:green"> ### 7.1 Mechanical safety </p>
        <p style="color:green"> In conjunction with the previous topics of physical capabilities of vehicles, it is imperative not to ignore the remaining crashes that are not due to human error in order to maximize safety gains. At present, the residual percentage (less than 10%) can be roughly attributed equally to vehicle and infrastructure faults or deficiencies. It is possible that this percentage will appear much more considerable after the human error is eliminated by a large amount by widespread AV use. </p>
    * https://road-safety.transport.ec.europa.eu/system/files/2021-07/ersosynthesis2018-autonomoussafety.pdf

Lookups:
https://ukeke.calvin.edu/cgi-bin/UDT/driver_2023.pl?query=engineers+outside+of+space+industry+taking+inspiration+from+the+space+industry&target=ebsco
responsibility controversy self-driving car industry


